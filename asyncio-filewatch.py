import asyncio
import os
import subprocess
import sys
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from threading import Thread

N_PROC = 10


class Process(object):
    """Collects some process information."""

    def __init__(self, proc, logfile, running):
        self.proc = proc
        self.logfile = logfile
        self.running = running


# Also see https://stackoverflow.com/questions/33824359/read-file-line-by-line-with-asyncio

# Pool for offloading I/O work in coroutines
io_pool_exc = ThreadPoolExecutor(max(os.cpu_count() * 5, N_PROC))


async def watch_logfile(loop, p):
    """Coroutine watching a logfile `p.logfile` and counting lines containing ERROR.
    Runs until the process is dead and returns the error count.
    """
    with open(p.logfile, 'r') as f_in:
        errcnt = 0
        while True:
            line = await loop.run_in_executor(io_pool_exc, f_in.readline)
            if not line:
                if not p.running:
                    break  # Nothing to read and process dead
                await asyncio.sleep(1)  # wait for more data
            elif "ERROR" in line:
                errcnt += 1
        return p.proc.pid, errcnt


def watch_async(procs):
    """Watch all logs generated by the procs 'asynchronously'. In fact, this is quite a ridiculous
    exercise: asyncio does not allow (under Windows at least) asynchronous file I/O. So all our
    funny coroutines are doing is delegate their work to a ThreadPoolExecutor and do busy polling on
    the results of the readline call. :(
    """
    if sys.platform == 'win32':
        asyncio.set_event_loop(asyncio.ProactorEventLoop())
    loop = asyncio.get_event_loop()
    results = loop.run_until_complete(asyncio.gather(*[watch_logfile(loop, p) for p in procs]))
    counts = [c for _, c in results]
    print("Average number of ERRORs:", sum(counts) / len(counts))


def main():
    # Start some processes generating logs. All without asyncio magic yet. We just want them to write to the
    # files we're gonna watch.
    procs = []
    for i in range(N_PROC):
        logfile = "logs/log.%03d.tmp" % i
        with open(logfile, "wb") as f_out:
            p = subprocess.Popen(['python', 'log-generator.py', '10'], stdout=f_out)
            procs.append(Process(p, logfile, True))
    print("Started %d logger processes:\n  %s" % (len(procs), '\n  '.join('PID %d: %s' % (p.proc.pid, p.logfile)
                                                                          for p in procs)))
    print("Starting at %s" % datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3])
    # Run in separate thread so main thread can keep an eye on the processes
    t = Thread(target=lambda: watch_async(procs))
    t.start()
    for p in procs:
        p.proc.wait()
        p.running = False
    t.join()
    print("Finished at %s" % datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3])


if __name__ == "__main__":
    main()
